{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据获取和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据是一个一个的csv文件，每个csv文件保存了一个5s的sequence，包含了多个车辆的轨迹信息\n",
    "DATASET_PATH = \"/ssd/datasets/argoverse/argoverse-forecasting-dataset/\"\n",
    "TRAIN = DATASET_PATH + \"train/data\"\n",
    "VAL = DATASET_PATH + \"val/data\"\n",
    "TEST = DATASET_PATH + \"test_obs/data/\"\n",
    "\n",
    "def data_process(root_dir):\n",
    "    t = time()\n",
    "    \n",
    "    root_dir = pathlib.Path(root_dir)\n",
    "    paths = [(root_dir / filename).absolute() for filename in os.listdir(root_dir)]\n",
    "    features = []\n",
    "    for path in paths:\n",
    "        sequence = pd.read_csv(path)\n",
    "        agent_x = sequence[sequence[\"OBJECT_TYPE\"] == \"AGENT\"][\"X\"]\n",
    "        agent_y = sequence[sequence[\"OBJECT_TYPE\"] == \"AGENT\"][\"Y\"]\n",
    "        xy = np.column_stack((agent_x, agent_y))\n",
    "        # 如果是train或者val，则xy shape: (50, 2) 记录了5秒（每秒10帧）的agent xy坐标\n",
    "        # 否则xy shape: (20, 2)\n",
    "        vel = xy[1:] - xy[:-1]\n",
    "        init_unknown_vel = np.array([np.nan, np.nan])\n",
    "        vel = np.vstack((init_unknown_vel, vel))\n",
    "        # vel shape: (50, 2)，差分得到速度，初始速度无法获取，设为NaN\n",
    "        feature = np.column_stack((xy, vel))\n",
    "        # feature shape: (50, 4), 各列分别是x, y, vel_x, vel_y\n",
    "        features.append(feature)\n",
    "    print(\"use {}s to process\".format(time() - t))\n",
    "    print(\"total num of sequences: {}\".format(len(features)))\n",
    "    return features\n",
    "\n",
    "def save_features_to_pkl(features, fliepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pkl.dump(features, f)\n",
    "        \n",
    "def load_pkl_features(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        features = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train /ssd/datasets/argoverse/argoverse-forecasting-dataset/train/data\n",
      "val /ssd/datasets/argoverse/argoverse-forecasting-dataset/val/data\n",
      "test /ssd/datasets/argoverse/argoverse-forecasting-dataset/test_obs/data/\n"
     ]
    }
   ],
   "source": [
    "d = {\"train\": TRAIN,\n",
    "     \"val\": VAL,\n",
    "     \"test\": TEST} \n",
    "for name, path in d.items():\n",
    "    print(name)\n",
    "    features = data_process(path)\n",
    "    save_features_to_pkl(features, name + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
